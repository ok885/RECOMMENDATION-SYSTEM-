{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa6ff3a",
   "metadata": {},
   "source": [
    "# ðŸ“š Interactive Book Recommender (User-Based Filtering)\n",
    "This notebook generates the `.pkl` files used in your Flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b759d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 2: Load the datasets\n",
    "books = pd.read_csv('books.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "users = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7059d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 3: Clean and rename columns\n",
    "books.rename(columns={'Book-Title': 'Title', 'Book-Author': 'Author', 'Image-URL-M': 'Image'}, inplace=True)\n",
    "ratings.rename(columns={'Book-Rating': 'Rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d35308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 4: Filter users with more than 50 ratings\n",
    "ratings = ratings[ratings['Rating'] > 0]\n",
    "active_users = ratings['User-ID'].value_counts() > 50\n",
    "ratings = ratings[ratings['User-ID'].isin(active_users[active_users].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 5: Merge ratings with book info\n",
    "merged_data = ratings.merge(books, on='ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e492d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 6: Create user-book matrix\n",
    "user_book_matrix = merged_data.pivot_table(index='User-ID', columns='Title', values='Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 7: Compute user similarity matrix\n",
    "user_similarity = cosine_similarity(user_book_matrix)\n",
    "np.fill_diagonal(user_similarity, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 8: Top books for homepage\n",
    "top_books = merged_data.groupby('Title').agg({'Rating': ['count', 'mean']})\n",
    "top_books.columns = ['RatingCount', 'AverageRating']\n",
    "top_books = top_books.sort_values('RatingCount', ascending=False).head(50)\n",
    "top_books = top_books.merge(books[['Title', 'Author', 'Image']].drop_duplicates('Title'), on='Title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 9: Save everything for Flask app\n",
    "pickle.dump(user_book_matrix, open('user_book_matrix.pkl', 'wb'))\n",
    "pickle.dump(user_similarity, open('user_similarity.pkl', 'wb'))\n",
    "pickle.dump(top_books, open('top_books.pkl', 'wb'))\n",
    "pickle.dump(books, open('book_details.pkl', 'wb'))\n",
    "\n",
    "print(\"âœ… All files generated! You can now run app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cece1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 10: Evaluate with Precision@5\n",
    "# We'll randomly pick a few users and check how many recommended books they actually rated highly\n",
    "\n",
    "def precision_at_k(user_id, k=5):\n",
    "    try:\n",
    "        index = np.where(user_book_matrix.index == user_id)[0][0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    similar_users = sorted(list(enumerate(user_similarity[index])), key=lambda x: x[1], reverse=True)[1:4]\n",
    "    recommended_books = set()\n",
    "\n",
    "    for sim_user in similar_users:\n",
    "        sim_user_id = user_book_matrix.index[sim_user[0]]\n",
    "        sim_ratings = user_book_matrix.loc[sim_user_id]\n",
    "        top_books = sim_ratings[sim_ratings > 8].sort_values(ascending=False).index\n",
    "        for book in top_books:\n",
    "            if book not in recommended_books:\n",
    "                recommended_books.add(book)\n",
    "            if len(recommended_books) >= k:\n",
    "                break\n",
    "        if len(recommended_books) >= k:\n",
    "            break\n",
    "\n",
    "    actual_user_books = user_book_matrix.loc[user_id]\n",
    "    liked_books = set(actual_user_books[actual_user_books > 8].index)\n",
    "\n",
    "    if not liked_books:\n",
    "        return None\n",
    "\n",
    "    hits = len(recommended_books & liked_books)\n",
    "    return hits / k\n",
    "\n",
    "# Run evaluation for a few users\n",
    "sample_users = user_book_matrix.index[:10]\n",
    "precisions = [precision_at_k(uid) for uid in sample_users if precision_at_k(uid) is not None]\n",
    "\n",
    "if precisions:\n",
    "    print(f\"âœ… Average Precision@5 for 10 sample users: {round(np.mean(precisions), 2)}\")\n",
    "else:\n",
    "    print(\"Not enough data to evaluate precision.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
